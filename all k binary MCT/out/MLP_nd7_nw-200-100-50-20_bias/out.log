batch_size = 100
bias = True
clear_checkpoint = False
clip_grad = 0
cuda = -1
device = cpu
dtype = float64
lr = 0.2
max_step = 1000
n_in = 303
n_out = 2
net_depth = 7
net_width = (200, 100, 50, 20)
no_stdout = False
optimizer = adam
out_dir = out
out_filename = out/MLP_nd7_nw-200-100-50-20_bias/out
out_infix = 
print_step = 5
save_step = 100
seed = 12694943
tolerance = 0.002

MLP(
  (net): Sequential(
    (0): Linear(in_features=303, out_features=200, bias=True)
    (1): ReLU()
    (2): Linear(in_features=200, out_features=100, bias=True)
    (3): ReLU()
    (4): Linear(in_features=100, out_features=50, bias=True)
    (5): ReLU()
    (6): Linear(in_features=50, out_features=20, bias=True)
    (7): ReLU()
    (8): Linear(in_features=20, out_features=2, bias=True)
  )
)

Total number of trainable parameters: 87012
init_time = 0.000
Training...
step = 0, loss = 0.058590857, r2_train = 0.89396103, r2_test = 0.89115186, train_time = 3.160, used_time = 3.574
step = 5, loss = 0.0022115587, r2_train = 0.98915535, r2_test = 0.9889199, train_time = 2.995, used_time = 21.223
step = 10, loss = 0.0018990355, r2_train = 0.97180168, r2_test = 0.97165857, train_time = 3.012, used_time = 38.971
step = 15, loss = 0.0013821793, r2_train = 0.99489108, r2_test = 0.9947021, train_time = 2.994, used_time = 56.629
step = 20, loss = 0.0011480404, r2_train = 0.99419781, r2_test = 0.99413041, train_time = 3.194, used_time = 75.221
step = 25, loss = 0.0011907483, r2_train = 0.99480843, r2_test = 0.99466407, train_time = 3.169, used_time = 93.712
step = 30, loss = 0.0011762519, r2_train = 0.99558078, r2_test = 0.99536377, train_time = 3.384, used_time = 113.440
step = 35, loss = 0.0013059652, r2_train = 0.99507563, r2_test = 0.9949378, train_time = 3.602, used_time = 134.304
step = 40, loss = 0.0010886929, r2_train = 0.99160193, r2_test = 0.99133283, train_time = 3.803, used_time = 156.194
step = 45, loss = 0.0012497824, r2_train = 0.99549166, r2_test = 0.9954348, train_time = 3.800, used_time = 178.062
